# DEEP LEARNING FOR VISUAL TRACKING

This notebook aim to gather the contributions of both group working on deep learning approach to visually track
an object in a video. Two different framework were used : GOTURN and YOLO.

The architecture used by GOTURN algorithm is described in the original paper :  

**[Learning to Track at 100 FPS with Deep Regression Networks](http://davheld.github.io/GOTURN/GOTURN.html)**,
<br>
[David Held](http://davheld.github.io/),
[Sebastian Thrun](http://robots.stanford.edu/),
[Silvio Savarese](http://cvgl.stanford.edu/silvio/),
<br>

The authors has implemented it with caffe  :
**[davheld/GOTURN](https://github.com/davheld/GOTURN)**

The tensorflow implementation that has been used to develop our own code: 
**[tangyuhao/GOTURN-Tensorflow ](https://github.com/tangyuhao/GOTURN-Tensorflow )**

Illustration of how this network works:

<img src="https://github.com/tangyuhao/GOTURN-Tensorflow/blob/master/imgs/pull7f-web_e2.png?raw=true" width=85%>

## Repository of the project :

- Link to slides : **[Slides ](https://docs.google.com/presentation/d/1kjXItpXmZkRsIuvp_h3WrM2JI7drxxQ8FyROHSFQuCE/edit?usp=sharing)** 

___

- GOTURN implemented in a colab ipython Notebook can be found in the following : [Code](https://colab.research.google.com/drive/1faWd1fuwwL0gBQkDAlj8aNvuX6_s4AmO)

- YOLO Implemented in C :  **[Chay16/TrackingVideo ](https://github.com/Chay16/TrackingVideo)**  
